\chapter{Discussion and Conclusion}\label{ch:discussion-and-conclusion}

The objective of this thesis was to demonstrate the limitations of conventional
time series methods when dealing with irregularly sampled data.
Furthermore, we aimed to determine whether Gaussian processes could serve as a
viable approach for modeling time series with irregularly spaced observations,
using the BP time series as an illustrative example.

In the theoretical section of this thesis, we elucidated that while linear
regression methods for handling correlated errors do exist, readily available
implementations are primarily designed for equispaced data.
Consequently, we introduced GP regression as a method capable of modeling
time series in continuous time.

A simulation study was subsequently conducted to investigate
the suitability of GP regression for modeling the BP time series,
which featured irregularly spaced observations. We assessed the performance of
GP regression in estimating specific target measures and compared these
results with those obtained using baseline methods.
The key findings and implications are summarized in the following section.

The final section of this thesis presents the limitations of the
simulation study and suggest potential directions
for future research and improvement.

\section{Comparison of GP Regression and Baseline Methods}

Overall, when considering all downsampling patterns and target measures,
GP regression outperforms the baseline methods. This superiority is particularly
evident when calculating the mean over small time windows, such as one-hour and one-day means.
This performance can be attributed to the fact that GP regression explicitly models
the dependencies among BP values across different time points. Consequently,
the uncertainty predictions are based on the amount of data available at time
points that are highly correlated, either positively or negatively, with the time
point of prediction.
Since the degree of correlation depends on the proximity to the prediction point,
this results in larger CI when data density is low around the prediction point.

Linear regression, on the other hand, provides the narrowest CIs and maintains adequate
CI coverage for the one-week mean under large downsampling factors. However,
linear regression does not exhibit significant improvement with an increase in data.
This can be attributed to the inherent
limitations of the linear model, which can only capture a linear trend with a perfect sinusoidal
seasonal pattern. This characteristic makes the method less reliant on the amount of data available.

In contrast, spline regression is a non-parametric method and is thus more data-dependent.
Spline regression does not yield meaningful results under large downsampling factors,
except when estimating TTR, where the locally unstable BP estimates have a relatively smaller impact.
For the same reason, spline regression does not attempt to fit a cyclic pattern and therefore struggles with seasonal sampling.

Although GPs fall under the category of non-parametric methods, they offer the option to express
prior beliefs about the function of interest through the choice of kernel.
In our case, a function with a cyclic pattern with a periodicity of 24 hours, an AR component, and a long-term trend are favored.
This choice does not impose as many constraints on the predictions as linear regression does.
These properties make GP regression the ideal candidate for analyzing BP time series based on irregularly spaced samples.

Seasonal sampling leads, in all cases, to reduced performance.
Interestingly, in the face of seasonal sampling, more data generally leads to
a reduction in CI coverage and width for linear regression,
whereas for GP regression, CI coverage would increase,
and for spline regression, it would remain at the same level.


\section{Limitations and Future Work}

In the current study, GP regression is employed to estimate values generated from a GP itself.
This unique approach provides GP regression with a potential advantage over baseline methods.
To ensure a fairer comparison, we suggest the following:

\begin{itemize}
    \item Investigate entirely different methods for simulating BP values.
    Ideally, this method would also offer greater control over the simulated samples.
    Currently, when generating random samples from a GP, our ability to control the shape of the produced
    functions is limited to the choice of the kernel function.

    \item Investigate the implications of employing a misspecified kernel during estimation.
    We have consistently used the same combination of kernel types - specifically, RBF, Mat√©rn, and Periodic kernels -
    for both simulation and estimation, with only kernel hyperparameters adjusted.
    It would be intriguing to understand how sensitive predictive performance is to the mismatches in
    the kernel function.

    \item Investigate the influence
    of non-Gaussian measurement errors on predictive performance.
\end{itemize}

Additionally, expanding the scope of adversarial analysis to examine different
kernel and measurement noise combinations would provide valuable insights.
While some assumptions about the BP time series were based on real-world BP data,
the contributions of measurement errors and the autoregressive (AR) components
to real-world data remain largely uncertain.
It has been demonstrated that a larger AR component in the signal makes predictions
more challenging, and the same would apply if the simulated measurement noise were increased.
Thus, by varying the contributions of these different components,
we can gain a deeper understanding of the limits of the regression methods.

GP regression credible interval estimates were calculated based on the equal-tailed
credible interval (ETI). Another commonly used credible interval is
the highest posterior density interval (HDI), which yields different intervals,
particularly when dealing with asymmetric distributions - a scenario that might be expected for TTR.
Therefore, for the next simulation study, it is advisable to calculate both HDI and ETI
to determine which one is better suited to the specific problem at hand.

The company's specific areas of interest for further exploration include:

\begin{itemize}
    \item Simulation of a seasonal component that evolves over time.
    This can be achieved by multiplying the Periodic kernel, used so far for simulation,
    with another kernel that models this temporal evolution, such as an RBF kernel.

    \item Calculate day and night BP values. This task requires defining "day" and "night," a task that could be
    facilitated by incorporating the predicted cyclic component.

    \item Assess the computational complexity of the used regression methods

\end{itemize}






%    In the current configuration, spline regression consumes the most computational time.
%    This is because spline regession nees to be employed several time in order to identify
%    the degree of smoothing through cross validation and also estimating confidence itervals through
%    bootstrapping.

%The method used for spline regression should be fine-tuned.
%One could use ridge regression on the
%generated B-spline basis functions instead of OLS regression. In this case
%one would identify the penalty parameter $\lambda$ through cross validation and
%choose a fixed high enough number of knots.
%Instead of
%using OLS regression on the B-spline bases generated form the input times,
%choosing the number of knots of the splines through cross validation
%it is probably more common to generate B-spline bases and
%
%
%
%\begin{itemize}
%    \item Use other methods than GPs to simulate BP time series
%    \item Investigate the impact of misspecified kernel functions and the effect of adding npn-gaussian errors.
%    \item Simulate evolving seasonal component by multiply the periodic kernel with e.g. an RBF kernel
%    \item Since measurement error, the periodic and AR component are largely unknown,
%    investigate the impact of varying the relative contributions of the different kernels.
%    \item Use highest posterior density credible interval (HDI) instead of the equal-tailed interval.
%    \item Define day and night BP values with the aid of the predicted cyclic component
%    \item Investigate computational complexity of GP and baseline methods
%    \item Highest posterior density interval (HDI) (https://easystats.github.io/bayestestR/reference/hdi.html)
%    Equal-tailed interval (ETI) (https://easystats.github.io/bayestestR/reference/eti.html)
%
%\end{itemize}

