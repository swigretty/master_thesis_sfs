%! Author = gianna
%! Date = 06.04.23


\chapter{Characteristics of Time Series}

\section{Time Series Definition}

    A potentially unevenly spaced \textbf{time series} is a sequence of observation time and value pair $(t_i, x_i)$
    with strictly increasing observation times.
    Let $\mathbb{T}$ be a set of observation time points,
    then the sequence of random variables $(X_t: t \in \mathbb{T})$ or simply $(X_t)$ is a \textbf{time series process}
    with observation times $t \in \mathbb{T}$.
    More specifically:
\begin{itemize}
    \item $(X_t: t \in \{1, 2, \dots n\})$ refers to a discrete and equispaced time series of length n
    \item $(X_{t_i}: i \in \{1, 2, \dots n\})$ refers to an irregularly spaced time series of length n
    with observations at time points $t_1 < t_2 < \dots t_n$
    \item $(X_{t}: t \in (0, T])$ refers to a continuous time series
\end{itemize}

When $\mathbb{T}$ has finite length, we will often use a random column vector $\mathbf{X}$ to refer to
the time series process $(X_t)$.
Sometimes a time series model will be expressed as a random function $f: \mathbb{T} \to \mathbb{R}$ instead
of a collection of random variables.
Throughout the thesis, the term time series is used both to refer to the data $(x_t)$ and the process $(X_t)$ from which it is generated.

\section{Moments of a Time Series}\label{sec:time_series_moments}

A time series process $(X_t)$ is usually characterized by its first and second moment.

\begin{definition}(\citeauthor{brockwell_introduction_2016})\label{def:time_series_moments}
    The \textbf{mean function} of a time series $(X_t)$ is:
    \[
        \mu_X(t) = \ERW{X_t}
    \]
    The \textbf{covariance function} of a time series $(X_t)$ is:
    \[
        \gamma_X(r,s) = \COV{X_r, X_s} = \ERW{(X_r - \mu_X(r))(X_s-\mu_X(s))}
    \]
\end{definition}

\section{Stationarity}\label{sec:stationarity}

Given that one has only one observation $x_t$ per time point $t$,
a necessary condition to statistically learn from a time series is stationarity.

\begin{definition}(\citeauthor{brockwell_introduction_2016})
    A time series $(X_t)$ is strictly stationary iff
    the distribution of $(X_{t_1}, \dots X_{t_n})$ is identical to the distribution of
    $(X_{t_{1+h}}, \dots ,X_{t_{n+h}})$ for all $n \in \mathbb{N}^{+}$
    and shifts $h \in \mathbb{Z}$:
\end{definition}


\begin{definition}(\citeauthor{brockwell_introduction_2016})
    A time series $(X_t)$ is weakly stationary if
    \[
        \mu_X(t) \text{ is independent of t,}
    \]
    and
    \[
        \gamma_X(t+h, t) \text{ is indpendent of $t$ for each $h$}
    \]
\end{definition}

Whenever the term stationary is used, it is referring to weak stationarity.

\section{Special cases of Time Series Processes}\label{sec:example-of-time-series-processes}

\begin{example} If $(X_t)$ is a \textbf{white noise} process,
    then $X_t \sim WN(0, \sigma^2)$, that is $X_t \sim F$ iid for some
    distribution $F$ with mean $0$ and varaince $\sigma^2$. A special case is Gaussian White
    noise where $W_t \sim \N(0, \sigma^2)$ and $F= \Phi$
\end{example}

\begin{example}
    An equispaced time series process $(X_t: t \in \{1,2, \dots\})$ is called \textbf{autoregressive process}
    of order p or AR(p) if:
    \[
        X_t = \phi_1 X_{t-1} + \dots + \phi_p X_{t-p} + W_t
    \]
    where $\phi_p \neq 0$ and $(W_t)$ is a white noise process.
    The variable $W_t$ is called the innovation at time $t$ and is independent of all $X_k$, $k < t$.
\end{example}

\begin{example}
    An equispaced time series process $(X_t: t \in \{1,2, \dots\})$ is called \textbf{moving average process}
    of order q or MA(q) if:
    \[
        X_t = W_t + \theta_1 W_{t-1} + \dots \theta_q W_{t-q}
    \]
    where $\theta_q \neq 0$ and $(W_t)$ is a white noise process.
    The variable $W_t$ is called the innovation at time $t$ and is independent of all $X_k$, $k < t$.
\end{example}


\begin{example}
    An equispaced time series process $(X_t: t \in \{1,2, \dots\})$ is called \textbf{autoregressive moving average process}
    of autoregressive order p and moving average oder q or ARMA(p,q) if:
    \[
        X_t =  \phi_1 X_{t-1} + \dots + \phi_p X_{t-p} + \theta_1 W_{t-1} + \dots \theta_q W_{t-q} + W_t
    \]
    where $\phi_p \neq 0, \theta_q \neq 0$ and $(W_t)$ is a white noise process.
    The variable $W_t$ is called the innovation at time $t$ and is independent of all $X_k$, $k < t$

\end{example}




\section{Characteristics of the Blood Pressure Time Series and Observations}\label{sec:characteristics-of-the-blood-pressure-time-series}

This section is listing the assumed properties
of a systolic blood pressure (BP) time series process and
the Aktiia bracelet measurements that we have from such a series.

The properties of the measurments can be extracted from Aktiia's
user data but for the underlying time series process one can
only make assumptions.

For the sake of this thesis, a BP time series process,
is expected to be the sum of the following components:
\begin{itemize}
    \item A seasonal component representing the circadian cycle since BP is known to be higher during the day then during the night
    which is potentially evolving.
    \item An autoregressive component
    \item A long term trend
\end{itemize}


Based on the Aktiia user data, the following properties of
the blood pressure measurements have been identified:
\begin{enumerate}
    \item Measurements are irregularly spaced, i.e. the time between two consecutive measurements varies
    \item Measurements are not uniformly sampled across time but the density of the observations should
    follow the circadian cycle (seasonal sampling)
    \item The sampling frequency varies from 0.5 to 4 measurements per hour
    \item The difference between the average day and average night BP measurements is between
    0 and 20 mmHg and is on average 10 mmHg.
    \item The mean BP overall users is 120 mmHg
    \item The within subject one-week sample variance is between 16 and 144 mmHg² and is on average 49 mmHg².
    \item \label{it:measurement_noise} The measured variance of the differences between Atkiia measurements
    and some reference is 62 mmHg^2.
\end{enumerate}

The Atkiia measurments $Y(x)$ at some time point $x$ are assumed to be the
sum of the true BP value $f(x)$
with some additional iid measurement noise $\epsilon$:

\begin{align*}
    Y(x) = f(x) + \epsilon && \epsilon_1 \dots \epsilon_n \iidsim \N(0, \sigma_n^{2})
\end{align*}

Based on point \ref{it:measurement_noise} variance $\sigma_n^{2}$
of the measurement noise is expected to be 31 mmHg². This follows
from the assumption that the measurement noise variance of the reference method
($Var(BP_{Ref}$) equals that of the Aktiia measurements $Var(BP_{Aktiia}$
and that $COV(Noise_{Ref}, Noise_{Aktiia})=0$

\begin{gather*}
    Var(BP_{Ref} - BP_{Aktiia}) = 62 mmHg^2 =
    Var(Noise_{Ref} - Noise_{Aktiia})
    = Var(Noise_{Ref}) + Var(Noise_{Aktiia}) - 2COV(Noise_{Ref}, Noise_{Aktiia})
\end{gather*}




